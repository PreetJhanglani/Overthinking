{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef4a72a-5119-413d-8a06-4ee952cbfcce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformer_lens\n",
      "  Downloading transformer_lens-2.15.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformer_lens) (1.4.0)\n",
      "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
      "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
      "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting datasets>=2.7.1 (from transformer_lens)\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting einops>=0.6.0 (from transformer_lens)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
      "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformer_lens) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformer_lens) (2.2.1)\n",
      "Collecting rich>=12.6.0 (from transformer_lens)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformer_lens) (0.2.0)\n",
      "Requirement already satisfied: torch>=2.2 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformer_lens) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformer_lens) (4.65.0)\n",
      "Requirement already satisfied: transformers>=4.43 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformer_lens) (4.49.0)\n",
      "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer_lens)\n",
      "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting typeguard<5.0,>=4.2 (from transformer_lens)\n",
      "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformer_lens) (4.12.2)\n",
      "Collecting wandb>=0.13.5 (from transformer_lens)\n",
      "  Downloading wandb-0.19.10-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (3.13.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.7.1->transformer_lens)\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests>=2.32.2 (from datasets>=2.7.1->transformer_lens)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.64.1 (from transformer_lens)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer_lens)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (3.10.9)\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
      "  Downloading wadler_lindig-0.1.5-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from pandas>=1.1.5->transformer_lens) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from pandas>=1.1.5->transformer_lens) (2023.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.6.0->transformer_lens)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from rich>=12.6.0->transformer_lens) (2.15.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from torch>=2.2->transformer_lens) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from torch>=2.2->transformer_lens) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from torch>=2.2->transformer_lens) (68.2.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from torch>=2.2->transformer_lens) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from sympy==1.13.1->torch>=2.2->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from tqdm>=4.64.1->transformer_lens) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformers>=4.43->transformer_lens) (2024.4.16)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from transformers>=4.43->transformer_lens) (0.21.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (8.1.8)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (3.10.0)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (2.11.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading sentry_sdk-2.27.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb>=0.13.5->transformer_lens)\n",
      "  Downloading setproctitle-1.3.5-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.13.1)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\preet\\.conda\\envs\\nle\\lib\\site-packages (from jinja2->torch>=2.2->transformer_lens) (2.1.3)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading transformer_lens-2.15.0-py3-none-any.whl (189 kB)\n",
      "   ---------------------------------------- 0.0/189.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 189.2/189.2 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
      "   ---------------------------------------- 0.0/739.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 739.7/739.7 kB 22.8 MB/s eta 0:00:00\n",
      "Downloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "   ---------------------------------------- 0.0/491.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 491.2/491.2 kB 30.1 MB/s eta 0:00:00\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.4/64.4 kB ? eta 0:00:00\n",
      "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.4/55.4 kB ? eta 0:00:00\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 243.2/243.2 kB ? eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Downloading wandb-0.19.10-py3-none-win_amd64.whl (20.7 MB)\n",
      "   ---------------------------------------- 0.0/20.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.3/20.7 MB 48.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 4.7/20.7 MB 50.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 7.0/20.7 MB 49.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 9.3/20.7 MB 49.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 11.7/20.7 MB 50.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 14.2/20.7 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 16.7/20.7 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 19.1/20.7 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 20.7/20.7 MB 46.7 MB/s eta 0:00:00\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/207.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 207.6/207.6 kB ? eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB ? eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "   ---------------------------------------- 0.0/146.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 146.7/146.7 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 431.0/431.0 kB ? eta 0:00:00\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.7/25.3 MB 55.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 4.2/25.3 MB 53.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.7/25.3 MB 53.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.3/25.3 MB 53.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.8/25.3 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.3/25.3 MB 54.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.7/25.3 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.7/25.3 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.1/25.3 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.6/25.3 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 59.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB ? eta 0:00:00\n",
      "Downloading sentry_sdk-2.27.0-py2.py3-none-any.whl (340 kB)\n",
      "   ---------------------------------------- 0.0/340.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 340.8/340.8 kB 20.7 MB/s eta 0:00:00\n",
      "Downloading wadler_lindig-0.1.5-py3-none-any.whl (20 kB)\n",
      "Downloading setproctitle-1.3.5-cp312-cp312-win_amd64.whl (12 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB ? eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: transformers-stream-generator\n",
      "  Building wheel for transformers-stream-generator (setup.py): started\n",
      "  Building wheel for transformers-stream-generator (setup.py): finished with status 'done'\n",
      "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12448 sha256=e69fa5f82c7c969b255aab658524cd8ccf3b13feba9cbf8e80e311702502f938\n",
      "  Stored in directory: c:\\users\\preet\\appdata\\local\\pip\\cache\\wheels\\a8\\58\\d2\\014cb67c3cc6def738c1b1635dbf4e3dab6fb63aba7070dce0\n",
      "Successfully built transformers-stream-generator\n",
      "Installing collected packages: better-abc, xxhash, wadler-lindig, typeguard, tqdm, smmap, setproctitle, sentry-sdk, requests, pyarrow, protobuf, mdurl, fancy-einsum, einops, docker-pycreds, dill, beartype, multiprocess, markdown-it-py, jaxtyping, gitdb, rich, gitpython, wandb, datasets, transformers-stream-generator, transformer_lens\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed beartype-0.14.1 better-abc-0.0.3 datasets-3.5.0 dill-0.3.8 docker-pycreds-0.4.0 einops-0.8.1 fancy-einsum-0.0.3 gitdb-4.0.12 gitpython-3.1.44 jaxtyping-0.3.2 markdown-it-py-3.0.0 mdurl-0.1.2 multiprocess-0.70.16 protobuf-6.30.2 pyarrow-19.0.1 requests-2.32.3 rich-14.0.0 sentry-sdk-2.27.0 setproctitle-1.3.5 smmap-5.0.2 tqdm-4.67.1 transformer_lens-2.15.0 transformers-stream-generator-0.0.5 typeguard-4.4.2 wadler-lindig-0.1.5 wandb-0.19.10 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee654116-d786-4300-b693-6a47922536c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B not found. Valid official model names (excl aliases): ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl', 'distilgpt2', 'facebook/opt-125m', 'facebook/opt-1.3b', 'facebook/opt-2.7b', 'facebook/opt-6.7b', 'facebook/opt-13b', 'facebook/opt-30b', 'facebook/opt-66b', 'EleutherAI/gpt-neo-125M', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-2.7B', 'EleutherAI/gpt-j-6B', 'EleutherAI/gpt-neox-20b', 'stanford-crfm/alias-gpt2-small-x21', 'stanford-crfm/battlestar-gpt2-small-x49', 'stanford-crfm/caprica-gpt2-small-x81', 'stanford-crfm/darkmatter-gpt2-small-x343', 'stanford-crfm/expanse-gpt2-small-x777', 'stanford-crfm/arwen-gpt2-medium-x21', 'stanford-crfm/beren-gpt2-medium-x49', 'stanford-crfm/celebrimbor-gpt2-medium-x81', 'stanford-crfm/durin-gpt2-medium-x343', 'stanford-crfm/eowyn-gpt2-medium-x777', 'EleutherAI/pythia-14m', 'EleutherAI/pythia-31m', 'EleutherAI/pythia-70m', 'EleutherAI/pythia-160m', 'EleutherAI/pythia-410m', 'EleutherAI/pythia-1b', 'EleutherAI/pythia-1.4b', 'EleutherAI/pythia-2.8b', 'EleutherAI/pythia-6.9b', 'EleutherAI/pythia-12b', 'EleutherAI/pythia-70m-deduped', 'EleutherAI/pythia-160m-deduped', 'EleutherAI/pythia-410m-deduped', 'EleutherAI/pythia-1b-deduped', 'EleutherAI/pythia-1.4b-deduped', 'EleutherAI/pythia-2.8b-deduped', 'EleutherAI/pythia-6.9b-deduped', 'EleutherAI/pythia-12b-deduped', 'EleutherAI/pythia-70m-v0', 'EleutherAI/pythia-160m-v0', 'EleutherAI/pythia-410m-v0', 'EleutherAI/pythia-1b-v0', 'EleutherAI/pythia-1.4b-v0', 'EleutherAI/pythia-2.8b-v0', 'EleutherAI/pythia-6.9b-v0', 'EleutherAI/pythia-12b-v0', 'EleutherAI/pythia-70m-deduped-v0', 'EleutherAI/pythia-160m-deduped-v0', 'EleutherAI/pythia-410m-deduped-v0', 'EleutherAI/pythia-1b-deduped-v0', 'EleutherAI/pythia-1.4b-deduped-v0', 'EleutherAI/pythia-2.8b-deduped-v0', 'EleutherAI/pythia-6.9b-deduped-v0', 'EleutherAI/pythia-12b-deduped-v0', 'EleutherAI/pythia-160m-seed1', 'EleutherAI/pythia-160m-seed2', 'EleutherAI/pythia-160m-seed3', 'NeelNanda/SoLU_1L_v9_old', 'NeelNanda/SoLU_2L_v10_old', 'NeelNanda/SoLU_4L_v11_old', 'NeelNanda/SoLU_6L_v13_old', 'NeelNanda/SoLU_8L_v21_old', 'NeelNanda/SoLU_10L_v22_old', 'NeelNanda/SoLU_12L_v23_old', 'NeelNanda/SoLU_1L512W_C4_Code', 'NeelNanda/SoLU_2L512W_C4_Code', 'NeelNanda/SoLU_3L512W_C4_Code', 'NeelNanda/SoLU_4L512W_C4_Code', 'NeelNanda/SoLU_6L768W_C4_Code', 'NeelNanda/SoLU_8L1024W_C4_Code', 'NeelNanda/SoLU_10L1280W_C4_Code', 'NeelNanda/SoLU_12L1536W_C4_Code', 'NeelNanda/GELU_1L512W_C4_Code', 'NeelNanda/GELU_2L512W_C4_Code', 'NeelNanda/GELU_3L512W_C4_Code', 'NeelNanda/GELU_4L512W_C4_Code', 'NeelNanda/Attn_Only_1L512W_C4_Code', 'NeelNanda/Attn_Only_2L512W_C4_Code', 'NeelNanda/Attn_Only_3L512W_C4_Code', 'NeelNanda/Attn_Only_4L512W_C4_Code', 'NeelNanda/Attn-Only-2L512W-Shortformer-6B-big-lr', 'NeelNanda/SoLU_1L512W_Wiki_Finetune', 'NeelNanda/SoLU_4L512W_Wiki_Finetune', 'ArthurConmy/redwood_attn_2l', 'llama-7b-hf', 'llama-13b-hf', 'llama-30b-hf', 'llama-65b-hf', 'meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Llama-2-13b-hf', 'meta-llama/Llama-2-13b-chat-hf', 'meta-llama/Llama-2-70b-chat-hf', 'codellama/CodeLlama-7b-hf', 'codellama/CodeLlama-7b-Python-hf', 'codellama/CodeLlama-7b-Instruct-hf', 'meta-llama/Meta-Llama-3-8B', 'meta-llama/Meta-Llama-3-8B-Instruct', 'meta-llama/Meta-Llama-3-70B', 'meta-llama/Meta-Llama-3-70B-Instruct', 'meta-llama/Llama-3.1-70B', 'meta-llama/Llama-3.1-8B', 'meta-llama/Llama-3.1-8B-Instruct', 'meta-llama/Llama-3.1-70B-Instruct', 'meta-llama/Llama-3.2-1B', 'meta-llama/Llama-3.2-3B', 'meta-llama/Llama-3.2-1B-Instruct', 'meta-llama/Llama-3.2-3B-Instruct', 'meta-llama/Llama-3.3-70B-Instruct', 'Baidicoot/Othello-GPT-Transformer-Lens', 'google-bert/bert-base-cased', 'google-bert/bert-base-uncased', 'google-bert/bert-large-cased', 'google-bert/bert-large-uncased', 'roneneldan/TinyStories-1M', 'roneneldan/TinyStories-3M', 'roneneldan/TinyStories-8M', 'roneneldan/TinyStories-28M', 'roneneldan/TinyStories-33M', 'roneneldan/TinyStories-Instruct-1M', 'roneneldan/TinyStories-Instruct-3M', 'roneneldan/TinyStories-Instruct-8M', 'roneneldan/TinyStories-Instruct-28M', 'roneneldan/TinyStories-Instruct-33M', 'roneneldan/TinyStories-1Layer-21M', 'roneneldan/TinyStories-2Layers-33M', 'roneneldan/TinyStories-Instuct-1Layer-21M', 'roneneldan/TinyStories-Instruct-2Layers-33M', 'stabilityai/stablelm-base-alpha-3b', 'stabilityai/stablelm-base-alpha-7b', 'stabilityai/stablelm-tuned-alpha-3b', 'stabilityai/stablelm-tuned-alpha-7b', 'mistralai/Mistral-7B-v0.1', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mistral-Small-24B-Base-2501', 'mistralai/Mistral-Nemo-Base-2407', 'mistralai/Mixtral-8x7B-v0.1', 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'bigscience/bloom-560m', 'bigscience/bloom-1b1', 'bigscience/bloom-1b7', 'bigscience/bloom-3b', 'bigscience/bloom-7b1', 'bigcode/santacoder', 'Qwen/Qwen-1_8B', 'Qwen/Qwen-7B', 'Qwen/Qwen-14B', 'Qwen/Qwen-1_8B-Chat', 'Qwen/Qwen-7B-Chat', 'Qwen/Qwen-14B-Chat', 'Qwen/Qwen1.5-0.5B', 'Qwen/Qwen1.5-0.5B-Chat', 'Qwen/Qwen1.5-1.8B', 'Qwen/Qwen1.5-1.8B-Chat', 'Qwen/Qwen1.5-4B', 'Qwen/Qwen1.5-4B-Chat', 'Qwen/Qwen1.5-7B', 'Qwen/Qwen1.5-7B-Chat', 'Qwen/Qwen1.5-14B', 'Qwen/Qwen1.5-14B-Chat', 'Qwen/Qwen2-0.5B', 'Qwen/Qwen2-0.5B-Instruct', 'Qwen/Qwen2-1.5B', 'Qwen/Qwen2-1.5B-Instruct', 'Qwen/Qwen2-7B', 'Qwen/Qwen2-7B-Instruct', 'Qwen/Qwen2.5-0.5B', 'Qwen/Qwen2.5-0.5B-Instruct', 'Qwen/Qwen2.5-1.5B', 'Qwen/Qwen2.5-1.5B-Instruct', 'Qwen/Qwen2.5-3B', 'Qwen/Qwen2.5-3B-Instruct', 'Qwen/Qwen2.5-7B', 'Qwen/Qwen2.5-7B-Instruct', 'Qwen/Qwen2.5-14B', 'Qwen/Qwen2.5-14B-Instruct', 'Qwen/Qwen2.5-32B', 'Qwen/Qwen2.5-32B-Instruct', 'Qwen/Qwen2.5-72B', 'Qwen/Qwen2.5-72B-Instruct', 'Qwen/QwQ-32B-Preview', 'microsoft/phi-1', 'microsoft/phi-1_5', 'microsoft/phi-2', 'microsoft/Phi-3-mini-4k-instruct', 'microsoft/phi-4', 'google/gemma-2b', 'google/gemma-7b', 'google/gemma-2b-it', 'google/gemma-7b-it', 'google/gemma-2-2b', 'google/gemma-2-2b-it', 'google/gemma-2-9b', 'google/gemma-2-9b-it', 'google/gemma-2-27b', 'google/gemma-2-27b-it', '01-ai/Yi-6B', '01-ai/Yi-34B', '01-ai/Yi-6B-Chat', '01-ai/Yi-34B-Chat', 'google-t5/t5-small', 'google-t5/t5-base', 'google-t5/t5-large', 'ai-forever/mGPT']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_lens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HookedTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load a pre-trained GPT-2 small model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m HookedTransformer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-ai/DeepSeek-R1-Distill-Llama-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\NLE\\Lib\\site-packages\\transformer_lens\\HookedTransformer.py:1312\u001b[0m, in \u001b[0;36mHookedTransformer.from_pretrained\u001b[1;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, first_n_layers, **from_pretrained_kwargs)\u001b[0m\n\u001b[0;32m   1309\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16 models may not work on CPU. Consider using a GPU or bfloat16.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Get the model name used in HuggingFace, rather than the alias.\u001b[39;00m\n\u001b[1;32m-> 1312\u001b[0m official_model_name \u001b[38;5;241m=\u001b[39m loading\u001b[38;5;241m.\u001b[39mget_official_model_name(model_name)\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;66;03m# Load the config into an HookedTransformerConfig object. If loading from a\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;66;03m# checkpoint, the config object will contain the information about the\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;66;03m# checkpoint\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m cfg \u001b[38;5;241m=\u001b[39m loading\u001b[38;5;241m.\u001b[39mget_pretrained_model_config(\n\u001b[0;32m   1318\u001b[0m     official_model_name,\n\u001b[0;32m   1319\u001b[0m     hf_cfg\u001b[38;5;241m=\u001b[39mhf_cfg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfrom_pretrained_kwargs,\n\u001b[0;32m   1329\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\NLE\\Lib\\site-packages\\transformer_lens\\loading_from_pretrained.py:735\u001b[0m, in \u001b[0;36mget_official_model_name\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m    733\u001b[0m official_model_name \u001b[38;5;241m=\u001b[39m model_alias_map\u001b[38;5;241m.\u001b[39mget(model_name\u001b[38;5;241m.\u001b[39mlower(), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m official_model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 735\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. Valid official model names (excl aliases): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOFFICIAL_MODEL_NAMES\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m     )\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m official_model_name\n",
      "\u001b[1;31mValueError\u001b[0m: deepseek-ai/DeepSeek-R1-Distill-Llama-8B not found. Valid official model names (excl aliases): ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl', 'distilgpt2', 'facebook/opt-125m', 'facebook/opt-1.3b', 'facebook/opt-2.7b', 'facebook/opt-6.7b', 'facebook/opt-13b', 'facebook/opt-30b', 'facebook/opt-66b', 'EleutherAI/gpt-neo-125M', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-2.7B', 'EleutherAI/gpt-j-6B', 'EleutherAI/gpt-neox-20b', 'stanford-crfm/alias-gpt2-small-x21', 'stanford-crfm/battlestar-gpt2-small-x49', 'stanford-crfm/caprica-gpt2-small-x81', 'stanford-crfm/darkmatter-gpt2-small-x343', 'stanford-crfm/expanse-gpt2-small-x777', 'stanford-crfm/arwen-gpt2-medium-x21', 'stanford-crfm/beren-gpt2-medium-x49', 'stanford-crfm/celebrimbor-gpt2-medium-x81', 'stanford-crfm/durin-gpt2-medium-x343', 'stanford-crfm/eowyn-gpt2-medium-x777', 'EleutherAI/pythia-14m', 'EleutherAI/pythia-31m', 'EleutherAI/pythia-70m', 'EleutherAI/pythia-160m', 'EleutherAI/pythia-410m', 'EleutherAI/pythia-1b', 'EleutherAI/pythia-1.4b', 'EleutherAI/pythia-2.8b', 'EleutherAI/pythia-6.9b', 'EleutherAI/pythia-12b', 'EleutherAI/pythia-70m-deduped', 'EleutherAI/pythia-160m-deduped', 'EleutherAI/pythia-410m-deduped', 'EleutherAI/pythia-1b-deduped', 'EleutherAI/pythia-1.4b-deduped', 'EleutherAI/pythia-2.8b-deduped', 'EleutherAI/pythia-6.9b-deduped', 'EleutherAI/pythia-12b-deduped', 'EleutherAI/pythia-70m-v0', 'EleutherAI/pythia-160m-v0', 'EleutherAI/pythia-410m-v0', 'EleutherAI/pythia-1b-v0', 'EleutherAI/pythia-1.4b-v0', 'EleutherAI/pythia-2.8b-v0', 'EleutherAI/pythia-6.9b-v0', 'EleutherAI/pythia-12b-v0', 'EleutherAI/pythia-70m-deduped-v0', 'EleutherAI/pythia-160m-deduped-v0', 'EleutherAI/pythia-410m-deduped-v0', 'EleutherAI/pythia-1b-deduped-v0', 'EleutherAI/pythia-1.4b-deduped-v0', 'EleutherAI/pythia-2.8b-deduped-v0', 'EleutherAI/pythia-6.9b-deduped-v0', 'EleutherAI/pythia-12b-deduped-v0', 'EleutherAI/pythia-160m-seed1', 'EleutherAI/pythia-160m-seed2', 'EleutherAI/pythia-160m-seed3', 'NeelNanda/SoLU_1L_v9_old', 'NeelNanda/SoLU_2L_v10_old', 'NeelNanda/SoLU_4L_v11_old', 'NeelNanda/SoLU_6L_v13_old', 'NeelNanda/SoLU_8L_v21_old', 'NeelNanda/SoLU_10L_v22_old', 'NeelNanda/SoLU_12L_v23_old', 'NeelNanda/SoLU_1L512W_C4_Code', 'NeelNanda/SoLU_2L512W_C4_Code', 'NeelNanda/SoLU_3L512W_C4_Code', 'NeelNanda/SoLU_4L512W_C4_Code', 'NeelNanda/SoLU_6L768W_C4_Code', 'NeelNanda/SoLU_8L1024W_C4_Code', 'NeelNanda/SoLU_10L1280W_C4_Code', 'NeelNanda/SoLU_12L1536W_C4_Code', 'NeelNanda/GELU_1L512W_C4_Code', 'NeelNanda/GELU_2L512W_C4_Code', 'NeelNanda/GELU_3L512W_C4_Code', 'NeelNanda/GELU_4L512W_C4_Code', 'NeelNanda/Attn_Only_1L512W_C4_Code', 'NeelNanda/Attn_Only_2L512W_C4_Code', 'NeelNanda/Attn_Only_3L512W_C4_Code', 'NeelNanda/Attn_Only_4L512W_C4_Code', 'NeelNanda/Attn-Only-2L512W-Shortformer-6B-big-lr', 'NeelNanda/SoLU_1L512W_Wiki_Finetune', 'NeelNanda/SoLU_4L512W_Wiki_Finetune', 'ArthurConmy/redwood_attn_2l', 'llama-7b-hf', 'llama-13b-hf', 'llama-30b-hf', 'llama-65b-hf', 'meta-llama/Llama-2-7b-hf', 'meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Llama-2-13b-hf', 'meta-llama/Llama-2-13b-chat-hf', 'meta-llama/Llama-2-70b-chat-hf', 'codellama/CodeLlama-7b-hf', 'codellama/CodeLlama-7b-Python-hf', 'codellama/CodeLlama-7b-Instruct-hf', 'meta-llama/Meta-Llama-3-8B', 'meta-llama/Meta-Llama-3-8B-Instruct', 'meta-llama/Meta-Llama-3-70B', 'meta-llama/Meta-Llama-3-70B-Instruct', 'meta-llama/Llama-3.1-70B', 'meta-llama/Llama-3.1-8B', 'meta-llama/Llama-3.1-8B-Instruct', 'meta-llama/Llama-3.1-70B-Instruct', 'meta-llama/Llama-3.2-1B', 'meta-llama/Llama-3.2-3B', 'meta-llama/Llama-3.2-1B-Instruct', 'meta-llama/Llama-3.2-3B-Instruct', 'meta-llama/Llama-3.3-70B-Instruct', 'Baidicoot/Othello-GPT-Transformer-Lens', 'google-bert/bert-base-cased', 'google-bert/bert-base-uncased', 'google-bert/bert-large-cased', 'google-bert/bert-large-uncased', 'roneneldan/TinyStories-1M', 'roneneldan/TinyStories-3M', 'roneneldan/TinyStories-8M', 'roneneldan/TinyStories-28M', 'roneneldan/TinyStories-33M', 'roneneldan/TinyStories-Instruct-1M', 'roneneldan/TinyStories-Instruct-3M', 'roneneldan/TinyStories-Instruct-8M', 'roneneldan/TinyStories-Instruct-28M', 'roneneldan/TinyStories-Instruct-33M', 'roneneldan/TinyStories-1Layer-21M', 'roneneldan/TinyStories-2Layers-33M', 'roneneldan/TinyStories-Instuct-1Layer-21M', 'roneneldan/TinyStories-Instruct-2Layers-33M', 'stabilityai/stablelm-base-alpha-3b', 'stabilityai/stablelm-base-alpha-7b', 'stabilityai/stablelm-tuned-alpha-3b', 'stabilityai/stablelm-tuned-alpha-7b', 'mistralai/Mistral-7B-v0.1', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mistral-Small-24B-Base-2501', 'mistralai/Mistral-Nemo-Base-2407', 'mistralai/Mixtral-8x7B-v0.1', 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'bigscience/bloom-560m', 'bigscience/bloom-1b1', 'bigscience/bloom-1b7', 'bigscience/bloom-3b', 'bigscience/bloom-7b1', 'bigcode/santacoder', 'Qwen/Qwen-1_8B', 'Qwen/Qwen-7B', 'Qwen/Qwen-14B', 'Qwen/Qwen-1_8B-Chat', 'Qwen/Qwen-7B-Chat', 'Qwen/Qwen-14B-Chat', 'Qwen/Qwen1.5-0.5B', 'Qwen/Qwen1.5-0.5B-Chat', 'Qwen/Qwen1.5-1.8B', 'Qwen/Qwen1.5-1.8B-Chat', 'Qwen/Qwen1.5-4B', 'Qwen/Qwen1.5-4B-Chat', 'Qwen/Qwen1.5-7B', 'Qwen/Qwen1.5-7B-Chat', 'Qwen/Qwen1.5-14B', 'Qwen/Qwen1.5-14B-Chat', 'Qwen/Qwen2-0.5B', 'Qwen/Qwen2-0.5B-Instruct', 'Qwen/Qwen2-1.5B', 'Qwen/Qwen2-1.5B-Instruct', 'Qwen/Qwen2-7B', 'Qwen/Qwen2-7B-Instruct', 'Qwen/Qwen2.5-0.5B', 'Qwen/Qwen2.5-0.5B-Instruct', 'Qwen/Qwen2.5-1.5B', 'Qwen/Qwen2.5-1.5B-Instruct', 'Qwen/Qwen2.5-3B', 'Qwen/Qwen2.5-3B-Instruct', 'Qwen/Qwen2.5-7B', 'Qwen/Qwen2.5-7B-Instruct', 'Qwen/Qwen2.5-14B', 'Qwen/Qwen2.5-14B-Instruct', 'Qwen/Qwen2.5-32B', 'Qwen/Qwen2.5-32B-Instruct', 'Qwen/Qwen2.5-72B', 'Qwen/Qwen2.5-72B-Instruct', 'Qwen/QwQ-32B-Preview', 'microsoft/phi-1', 'microsoft/phi-1_5', 'microsoft/phi-2', 'microsoft/Phi-3-mini-4k-instruct', 'microsoft/phi-4', 'google/gemma-2b', 'google/gemma-7b', 'google/gemma-2b-it', 'google/gemma-7b-it', 'google/gemma-2-2b', 'google/gemma-2-2b-it', 'google/gemma-2-9b', 'google/gemma-2-9b-it', 'google/gemma-2-27b', 'google/gemma-2-27b-it', '01-ai/Yi-6B', '01-ai/Yi-34B', '01-ai/Yi-6B-Chat', '01-ai/Yi-34B-Chat', 'google-t5/t5-small', 'google-t5/t5-base', 'google-t5/t5-large', 'ai-forever/mGPT']"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# Load a pre-trained GPT-2 small model\n",
    "model = HookedTransformer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82be31b-b71b-4f20-99c3-96c800cfb5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e80f069-0af8-4740-ac81-986e56d6259f",
   "metadata": {
    "id": "cfed6b27-e673-4f01-8a01-61339b6e1f63"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TextStreamer, set_seed\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af887366-3a29-4d88-8d8b-b45a82e65568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "random_seed = 42\n",
    "np_seed = 42\n",
    "torch_seed = 42\n",
    "transformers_seed = 42\n",
    "\n",
    "random.seed(random_seed)\n",
    "np.random.seed(np_seed)\n",
    "torch.manual_seed(torch_seed)\n",
    "set_seed(transformers_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73428fc-411d-4558-adb7-556f39e04f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    # llm_int8_enable_fp32_cpu_offload=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48582104-67ca-47b0-bd06-fd5268b77611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\")\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aea0bb0-b869-4ff6-b880-ef74d1da74bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd267e3fa9234dcda7c1e362bfaef4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60048661-51e9-4429-b1a6-482b4dcf9eeb",
   "metadata": {},
   "source": [
    "GPU Change: 5957Mib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3767c3-e425-443a-b08e-6ac491af43ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5332.508056640625\n"
     ]
    }
   ],
   "source": [
    "print(hf_model.get_memory_footprint()/1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8429b8e-ba1b-427f-a722-843d7f1d0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformerConfig, HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883e1fde-ae24-4ef8-b605-587ad2387018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TransformerLens configuration\n",
    "config = HookedTransformerConfig(\n",
    "    d_model=hf_model.config.hidden_size,\n",
    "    n_layers=hf_model.config.num_hidden_layers,\n",
    "    n_ctx=hf_model.config.max_position_embeddings,\n",
    "    d_head=hf_model.config.hidden_size // hf_model.config.num_attention_heads,\n",
    "    n_heads=hf_model.config.num_attention_heads,\n",
    "    d_mlp=hf_model.config.intermediate_size,\n",
    "    d_vocab=hf_model.config.vocab_size,\n",
    "    act_fn=\"silu\",  # Specify the activation function here\n",
    "    tokenizer_name=\"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",\n",
    "    model_name=\"DeepSeek-R1-Distill-Llama-8B\",\n",
    "    original_architecture=\"llama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "080eaa80-9883-4f93-83a2-00b1444b407b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 17179869184 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the TransformerLens model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m HookedTransformer(config)\n",
      "File \u001b[1;32m~\\.conda\\envs\\NLE\\Lib\\site-packages\\transformer_lens\\HookedTransformer.py:189\u001b[0m, in \u001b[0;36mHookedTransformer.__init__\u001b[1;34m(self, cfg, tokenizer, move_to_device, default_padding_side)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_hook_tokens:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_tokens \u001b[38;5;241m=\u001b[39m HookPoint()  \u001b[38;5;66;03m# [batch, pos]\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m--> 189\u001b[0m     [TransformerBlock(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg, block_index) \u001b[38;5;28;01mfor\u001b[39;00m block_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_layers)]\n\u001b[0;32m    190\u001b[0m )\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mnormalization_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_final \u001b[38;5;241m=\u001b[39m RMSNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n",
      "File \u001b[1;32m~\\.conda\\envs\\NLE\\Lib\\site-packages\\transformer_lens\\components\\transformer_block.py:78\u001b[0m, in \u001b[0;36mTransformerBlock.__init__\u001b[1;34m(self, cfg, block_index)\u001b[0m\n\u001b[0;32m     76\u001b[0m attention \u001b[38;5;241m=\u001b[39m Attention \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_key_value_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m GroupedQueryAttention\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_local_attn:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn \u001b[38;5;241m=\u001b[39m attention(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m, block_index)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\NLE\\Lib\\site-packages\\transformer_lens\\components\\attention.py:35\u001b[0m, in \u001b[0;36mAttention.__init__\u001b[1;34m(self, cfg, attn_type, layer_id)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     22\u001b[0m     cfg: Union[Dict, HookedTransformerConfig],\n\u001b[0;32m     23\u001b[0m     attn_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     layer_id: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m ):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Attention Block - params have shape [head_index, d_model, d_head] (or [head_index, d_head, d_model] for W_O) and multiply on the right. attn_scores refers to query key dot product immediately before attention softmax\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Convention: All attention pattern-style matrices have shape [batch, head_index, query_pos, key_pos]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m        layer_id (int, optional): The index of the current layer. Used by the Mistal models (labelled here as stanford-gpt2) to scale down attention scores pre softmax for numerical stability reasons by 1/(layer_id+1). Defaults to None.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(cfg, attn_type, layer_id)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m HookedTransformerConfig\u001b[38;5;241m.\u001b[39munwrap(cfg)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mload_in_4bit:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;66;03m# 4-bit quantization convention\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\NLE\\Lib\\site-packages\\transformer_lens\\components\\abstract_attention.py:82\u001b[0m, in \u001b[0;36mAbstractAttention.__init__\u001b[1;34m(self, cfg, attn_type, layer_id)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_type \u001b[38;5;241m=\u001b[39m attn_type\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Create a max_ctx x max_ctx mask, with True iff that query position\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# can attend to that key position (query is first axis, key is second axis)\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtril(torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_ctx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_ctx))\u001b[38;5;241m.\u001b[39mbool())\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# For global attention, this is a lower triangular matrix - key <= query\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m, causal_mask)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 17179869184 bytes."
     ]
    }
   ],
   "source": [
    "# Initialize the TransformerLens model\n",
    "model = HookedTransformer(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e9cde-d0d9-4fd5-8a2d-dbffe5548622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
